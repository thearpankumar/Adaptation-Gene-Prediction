{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 0: Setup and Library Imports\n",
        "# =============================================================================\n",
        "print(\"--- Part 0: Loading Libraries ---\")\n",
        "# Install dependencies if running for the first time\n",
        "# !pip install biopython scikit-learn pandas xgboost matplotlib imblearn joblib\n",
        "\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# Set display option for matplotlib in Jupyter\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# --- NEW: Import VarianceThreshold ---\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "tpHTX55_jFVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 1: Data Collection and Labeling\n",
        "# =============================================================================\n",
        "print(\"\\n--- Part 1: Collecting and Labeling Data ---\")\n",
        "gbk_file = \"GCF_000012145.1_ASM1214v1_genomic.gbff\"\n",
        "if not os.path.exists(gbk_file):\n",
        "    print(\"Downloading and decompressing GenBank file...\")\n",
        "    !wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/012/145/GCF_000012145.1_ASM1214v1/GCF_000012145.1_ASM1214v1_genomic.gbff.gz\n",
        "    !gunzip GCF_000012145.1_ASM1214v1_genomic.gbff.gz\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "stress_genes_positive = [\n",
        "    \"DR2340\", \"DR1089\", \"DRA0346\", \"DR0423\", \"DR1596\", \"DR1595\", \"DR2256\", \"DR1337\", \"DR0845\", \"DR1205\", \"DR1132\",\n",
        "    \"DR0757\", \"DR1720\", \"DR0325\", \"DR0828\", \"DRA0013\", \"DRA0014\", \"DRA0016\", \"DRA0017\", \"DR1289\", \"DR1126\", \"DR1477\",\n",
        "    \"DR1775\", \"DR1902\", \"DR0099\", \"DR0070\", \"DR1916\", \"DR2633\", \"DR0326\", \"DR0198\", \"DR0219\", \"DR1901\", \"DR2441\",\n",
        "    \"DRB0095\", \"DR1857\", \"DR0100\", \"DR0689\", \"DR0261\", \"DR2574\", \"DR1998\", \"DRB0100\", \"DR0003\", \"DR0505\", \"DR0596\",\n",
        "    \"DR1172\", \"DR0607\", \"DR0819\", \"DR2275\", \"DR2417\"\n",
        "]\n",
        "housekeeping_genes_negative = [\n",
        "    \"DR0001\", \"DR0002\", \"DR0004\", \"DR0005\", \"DR0006\", \"DR0010\", \"DR1343\", \"DR1344\", \"DR0634\", \"DR0635\", \"DR1796\",\n",
        "    \"DR0012\", \"DR0013\", \"DR0014\", \"DR0015\", \"DR0020\", \"DR0021\", \"DR0022\", \"DR0907\", \"DR0908\", \"DR1913\", \"DR1914\",\n",
        "    \"DR2088\", \"DR2089\", \"DR2090\", \"DR1262\", \"DR1263\", \"DR0016\", \"DR0017\", \"DR0023\", \"DR0024\", \"DR0102\", \"DR0103\",\n",
        "    \"DR1264\", \"DR1265\", \"DR2091\", \"DR2092\", \"DR0506\", \"DR0507\", \"DR0028\", \"DR0029\", \"DR0030\", \"DR0107\", \"DR0108\",\n",
        "    \"DR0109\", \"DR1268\", \"DR1269\", \"DR2095\", \"DR2096\", \"DR0508\", \"DR0509\", \"DR0110\", \"DR0111\", \"DR0112\"\n",
        "]\n",
        "keywords = [\n",
        "    \"repair\", \"stress\", \"tolerance\", \"resistance\", \"oxidative\", \"radiation\", \"dna\", \"antioxidant\", \"heat shock\",\n",
        "    \"cold shock\", \"desiccation\", \"uv\", \"gamma\", \"protection\", \"survival\", \"adaptation\", \"chaperone\",\n",
        "    \"detoxification\", \"redox\", \"homeostasis\", \"shock\", \"survivability\", \"resilience\", \"stabilization\", \"recovery\",\n",
        "    \"protective\", \"oxidoreductase\", \"peroxidase\", \"superoxide\", \"catalase\", \"stress-induced\"\n",
        "]\n",
        "labeled_genes = []\n",
        "records = list(SeqIO.parse(gbk_file, \"genbank\"))\n",
        "for record in records:\n",
        "    for feature in record.features:\n",
        "        if feature.type == \"CDS\":\n",
        "            gene_id = feature.qualifiers.get(\"locus_tag\", [None])[0]\n",
        "            if not gene_id: continue\n",
        "            product = feature.qualifiers.get(\"product\", [\"\"])[0].lower()\n",
        "            sequence = str(feature.extract(record.seq))\n",
        "            if len(sequence) % 3 != 0 or 'N' in sequence: continue\n",
        "            label = -1\n",
        "            if gene_id in stress_genes_positive or any(keyword in product for keyword in keywords):\n",
        "                label = 1\n",
        "            elif gene_id in housekeeping_genes_negative or \"ribosomal protein\" in product or \\\n",
        "                 any(term in product for term in [\"elongation factor\", \"tRNA synthetase\", \"gyrase\"]):\n",
        "                label = 0\n",
        "            if label != -1:\n",
        "                labeled_genes.append({\"id\": gene_id, \"sequence\": sequence, \"label\": label})\n",
        "df = pd.DataFrame(labeled_genes).drop_duplicates(subset=['id']).reset_index(drop=True)\n",
        "print(\"Cleaned Class Distribution:\")\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "AsBH0H7ijI90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 2: Feature Engineering\n",
        "# =============================================================================\n",
        "print(\"\\n--- Part 2: Engineering Features ---\")\n",
        "def get_protein_features(seq):\n",
        "    try:\n",
        "        translated_seq = seq.translate(to_stop=True)\n",
        "        if len(translated_seq) < 10: return 0, 0\n",
        "        protein_analyzer = ProteinAnalysis(str(translated_seq))\n",
        "        hydrophobicity = protein_analyzer.gravy()\n",
        "        isoelectric_point = protein_analyzer.isoelectric_point()\n",
        "        return hydrophobicity, isoelectric_point\n",
        "    except Exception:\n",
        "        return 0, 0\n",
        "def get_all_features(df):\n",
        "    basic_features_list = []\n",
        "    motifs = [r\"GTT[ATCG]CG\", r\"CG[ATCG]CG\", r\"TTC[ATCG][ATCG]GAA\", r\"CTG[ATCG][ATCG]GTC\"]\n",
        "    for seq in df['sequence']:\n",
        "        length = len(seq)\n",
        "        gc_content = (seq.count('G') + seq.count('C')) / length if length > 0 else 0\n",
        "        gc3 = sum(1 for i in range(2, len(seq), 3) if seq[i] in ['G', 'C']) / (length // 3) if length >= 3 else 0\n",
        "        cg_dinucleotide = seq.count(\"CG\") / (length - 1) if length > 1 else 0\n",
        "        motif_frequencies = [len(re.findall(motif, seq, re.IGNORECASE)) / length if length > 0 else 0 for motif in motifs]\n",
        "        hydrophobicity, isoelectric_point = get_protein_features(seq)\n",
        "        basic_features_list.append({\n",
        "            \"length\": length, \"gc_content\": gc_content, \"gc3\": gc3, \"cg_dinucleotide\": cg_dinucleotide,\n",
        "            \"motif_frequency_1\": motif_frequencies[0], \"motif_frequency_2\": motif_frequencies[1],\n",
        "            \"motif_frequency_3\": motif_frequencies[2], \"motif_frequency_4\": motif_frequencies[3],\n",
        "            \"hydrophobicity\": hydrophobicity, \"isoelectric_point\": isoelectric_point\n",
        "        })\n",
        "    basic_features_df = pd.DataFrame(basic_features_list)\n",
        "    kmer_vectorizer = CountVectorizer(min_df=0.02, ngram_range=(4, 4))\n",
        "    kmer_texts = [' '.join([seq[i:i+4] for i in range(len(seq) - 3)]) for seq in df['sequence']]\n",
        "    kmer_counts = kmer_vectorizer.fit_transform(kmer_texts)\n",
        "    kmer_features_df = pd.DataFrame(kmer_counts.toarray(), columns=kmer_vectorizer.get_feature_names_out())\n",
        "    full_feature_df = pd.concat([basic_features_df, kmer_features_df], axis=1)\n",
        "    return full_feature_df, kmer_vectorizer\n",
        "X, kmer_vectorizer = get_all_features(df)\n",
        "y = df['label']\n",
        "feature_columns = X.columns.tolist()\n",
        "print(f\"Total features engineered: {len(feature_columns)}\")\n"
      ],
      "metadata": {
        "id": "tyOf69SAjKxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 3: Preprocessing, Feature Selection, and Model Training (IMPROVED)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Part 3: Preprocessing and Training ---\")\n",
        "# Stratified train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# --- NEW STEP 1: Remove constant features ---\n",
        "print(\"Step 3a: Removing constant features...\")\n",
        "vt = VarianceThreshold(threshold=0.0)\n",
        "X_train_no_const = vt.fit_transform(X_train)\n",
        "X_test_no_const = vt.transform(X_test)\n",
        "# Keep track of the remaining column names\n",
        "columns_after_vt = X_train.columns[vt.get_support()]\n",
        "print(f\"Removed {X_train.shape[1] - X_train_no_const.shape[1]} constant features.\")\n",
        "\n",
        "# --- NEW STEP 2: Select top 100 features from the non-constant set ---\n",
        "print(\"Step 3b: Selecting top 100 features...\")\n",
        "selector = SelectKBest(f_classif, k=100)\n",
        "# Use the non-constant data for fitting\n",
        "X_train_selected = selector.fit_transform(X_train_no_const, y_train)\n",
        "X_test_selected = selector.transform(X_test_no_const)\n",
        "# Keep track of the final selected column names\n",
        "final_columns = columns_after_vt[selector.get_support()]\n",
        "\n",
        "# --- NEW STEP 3: Apply SMOTE ---\n",
        "print(\"Step 3c: Applying SMOTE to balance training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
        "\n",
        "# --- NEW STEP 4: Train model ---\n",
        "print(\"Step 3d: Performing GridSearchCV for hyperparameter tuning...\")\n",
        "param_grid = {'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.05, 0.1]}\n",
        "model_xgb = XGBClassifier(eval_metric='logloss', random_state=42, use_label_encoder=False)\n",
        "grid = GridSearchCV(model_xgb, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
        "grid.fit(X_train_resampled, y_train_resampled)\n",
        "final_model = grid.best_estimator_\n",
        "print(\"Best hyperparameters found:\", grid.best_params_)\n"
      ],
      "metadata": {
        "id": "zqnK42ZijMZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 4: Model Evaluation\n",
        "# =============================================================================\n",
        "print(\"\\n--- Part 4: Evaluating the Final Model ---\")\n",
        "y_pred = final_model.predict(X_test_selected)\n",
        "y_proba = final_model.predict_proba(X_test_selected)[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Control\", \"Stress\"]))"
      ],
      "metadata": {
        "id": "O1VJE5EijOE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 5: Saving All Model Artifacts for Future Use (IMPROVED)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Part 5: Saving Model and Pipeline Artifacts ---\")\n",
        "joblib.dump(final_model, 'stress_gene_model.joblib')\n",
        "# --- NEW: Save the variance thresholder ---\n",
        "joblib.dump(vt, 'variance_thresholder.joblib')\n",
        "joblib.dump(selector, 'feature_selector.joblib')\n",
        "joblib.dump(kmer_vectorizer, 'kmer_vectorizer.joblib')\n",
        "joblib.dump(feature_columns, 'feature_columns.joblib')\n",
        "print(\"✅ All artifacts saved successfully.\")"
      ],
      "metadata": {
        "id": "6gQpcVp0jP3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Part 6: Loading Artifacts and Predicting on 5 Samples (IMPROVED)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Part 6: Loading Artifacts and Demonstrating Prediction ---\")\n",
        "# Load all the components\n",
        "loaded_model = joblib.load('stress_gene_model.joblib')\n",
        "# --- NEW: Load the variance thresholder ---\n",
        "loaded_vt = joblib.load('variance_thresholder.joblib')\n",
        "loaded_selector = joblib.load('feature_selector.joblib')\n",
        "loaded_vectorizer = joblib.load('kmer_vectorizer.joblib')\n",
        "loaded_training_columns = joblib.load('feature_columns.joblib')\n",
        "print(\"✅ All artifacts re-loaded successfully.\\n\")\n",
        "\n",
        "sample_df = df.sample(n=5, random_state=42)\n",
        "label_map = {0: \"Control\", 1: \"Stress\"}\n",
        "for index, row in sample_df.iterrows():\n",
        "    gene_id = row['id']\n",
        "    true_label_numeric = row['label']\n",
        "    sequence = row['sequence']\n",
        "    print(f\"--- Predicting for Gene ID: {gene_id} ---\")\n",
        "    print(f\"True Label: {label_map[true_label_numeric]}\")\n",
        "\n",
        "    # Replicate the full feature engineering and preprocessing pipeline\n",
        "    single_gene_df = pd.DataFrame([{\"sequence\": sequence}])\n",
        "    basic_features_list = []\n",
        "    # (Re-using the feature generation logic for simplicity)\n",
        "    motifs = [r\"GTT[ATCG]CG\", r\"CG[ATCG]CG\", r\"TTC[ATCG][ATCG]GAA\", r\"CTG[ATCG][ATCG]GTC\"]\n",
        "    length = len(sequence); gc_content = (sequence.count('G') + sequence.count('C')) / length if length > 0 else 0\n",
        "    gc3 = sum(1 for i in range(2, len(sequence), 3) if sequence[i] in ['G', 'C']) / (length // 3) if length >= 3 else 0\n",
        "    cg_dinucleotide = sequence.count(\"CG\") / (length - 1) if length > 1 else 0\n",
        "    motif_frequencies = [len(re.findall(motif, sequence, re.IGNORECASE)) / length if length > 0 else 0 for motif in motifs]\n",
        "    hydrophobicity, isoelectric_point = get_protein_features(sequence)\n",
        "    basic_features_list.append({\n",
        "        \"length\": length, \"gc_content\": gc_content, \"gc3\": gc3, \"cg_dinucleotide\": cg_dinucleotide,\n",
        "        \"motif_frequency_1\": motif_frequencies[0], \"motif_frequency_2\": motif_frequencies[1],\n",
        "        \"motif_frequency_3\": motif_frequencies[2], \"motif_frequency_4\": motif_frequencies[3],\n",
        "        \"hydrophobicity\": hydrophobicity, \"isoelectric_point\": isoelectric_point\n",
        "    })\n",
        "    basic_features = pd.DataFrame(basic_features_list)\n",
        "    kmer_text = [' '.join([sequence[i:i+4] for i in range(len(sequence) - 3)])]\n",
        "    kmer_counts = loaded_vectorizer.transform(kmer_text)\n",
        "    kmer_features = pd.DataFrame(kmer_counts.toarray(), columns=loaded_vectorizer.get_feature_names_out())\n",
        "    single_feature_vector = pd.concat([basic_features, kmer_features], axis=1)\n",
        "    aligned_vector = single_feature_vector.reindex(columns=loaded_training_columns, fill_value=0)\n",
        "\n",
        "    # --- NEW: Apply the loaded preprocessors in the correct order ---\n",
        "    # 1. Apply VarianceThreshold\n",
        "    vector_no_const = loaded_vt.transform(aligned_vector)\n",
        "    # 2. Apply SelectKBest\n",
        "    selected_vector = loaded_selector.transform(vector_no_const)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = loaded_model.predict(selected_vector)[0]\n",
        "    probabilities = loaded_model.predict_proba(selected_vector)[0]\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Predicted Label: {label_map[prediction]}\")\n",
        "    print(f\"Model Confidence -> [P(Control): {probabilities[0]:.2f}, P(Stress): {probabilities[1]:.2f}]\")\n",
        "    if prediction == true_label_numeric: print(\"✅ Result: CORRECT\")\n",
        "    else: print(\"❌ Result: INCORRECT\")\n",
        "    print(\"-\" * 45 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyuVDJMHfcHo",
        "outputId": "d70889c0-602f-474d-db90-be8da42fa4fb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Part 0: Loading Libraries ---\n",
            "\n",
            "--- Part 1: Collecting and Labeling Data ---\n",
            "Cleaned Class Distribution:\n",
            "label\n",
            "1    126\n",
            "0     59\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Part 2: Engineering Features ---\n",
            "Total features engineered: 10792\n",
            "\n",
            "--- Part 3: Preprocessing and Training ---\n",
            "Step 3a: Removing constant features...\n",
            "Removed 2 constant features.\n",
            "Step 3b: Selecting top 100 features...\n",
            "Step 3c: Applying SMOTE to balance training data...\n",
            "Step 3d: Performing GridSearchCV for hyperparameter tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:13:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
            "\n",
            "--- Part 4: Evaluating the Final Model ---\n",
            "Accuracy: 0.7297297297297297\n",
            "ROC AUC Score: 0.7200000000000001\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Control       0.57      0.67      0.62        12\n",
            "      Stress       0.83      0.76      0.79        25\n",
            "\n",
            "    accuracy                           0.73        37\n",
            "   macro avg       0.70      0.71      0.70        37\n",
            "weighted avg       0.74      0.73      0.73        37\n",
            "\n",
            "\n",
            "--- Part 5: Saving Model and Pipeline Artifacts ---\n",
            "✅ All artifacts saved successfully.\n",
            "\n",
            "--- Part 6: Loading Artifacts and Demonstrating Prediction ---\n",
            "✅ All artifacts re-loaded successfully.\n",
            "\n",
            "--- Predicting for Gene ID: RF_RS01055 ---\n",
            "True Label: Stress\n",
            "Predicted Label: Stress\n",
            "Model Confidence -> [P(Control): 0.00, P(Stress): 1.00]\n",
            "✅ Result: CORRECT\n",
            "---------------------------------------------\n",
            "\n",
            "--- Predicting for Gene ID: RF_RS01585 ---\n",
            "True Label: Control\n",
            "Predicted Label: Control\n",
            "Model Confidence -> [P(Control): 0.96, P(Stress): 0.04]\n",
            "✅ Result: CORRECT\n",
            "---------------------------------------------\n",
            "\n",
            "--- Predicting for Gene ID: RF_RS06645 ---\n",
            "True Label: Stress\n",
            "Predicted Label: Stress\n",
            "Model Confidence -> [P(Control): 0.01, P(Stress): 0.99]\n",
            "✅ Result: CORRECT\n",
            "---------------------------------------------\n",
            "\n",
            "--- Predicting for Gene ID: RF_RS05080 ---\n",
            "True Label: Stress\n",
            "Predicted Label: Stress\n",
            "Model Confidence -> [P(Control): 0.00, P(Stress): 1.00]\n",
            "✅ Result: CORRECT\n",
            "---------------------------------------------\n",
            "\n",
            "--- Predicting for Gene ID: RF_RS06335 ---\n",
            "True Label: Control\n",
            "Predicted Label: Control\n",
            "Model Confidence -> [P(Control): 0.94, P(Stress): 0.06]\n",
            "✅ Result: CORRECT\n",
            "---------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}